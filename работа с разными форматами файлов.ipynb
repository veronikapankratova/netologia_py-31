{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'newsafr.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7c7e43a67820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mwords_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'newsafr.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-7c7e43a67820>\u001b[0m in \u001b[0;36mnews_reader\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnews_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mfile_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'newsafr.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def news_reader(file_name):\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        file_content = f.read()\n",
    "        content = json.loads(file_content)\n",
    "\n",
    "    text = content['rss']['channel']['items']\n",
    "\n",
    "    news_extract = []\n",
    "    for news_list in text:\n",
    "        news_line_extract = news_list['description']\n",
    "        news_extract.append(news_line_extract)\n",
    "\n",
    "    return news_extract\n",
    "\n",
    "\n",
    "def words_counter(news_string):\n",
    "\n",
    "    words = []\n",
    "    for news in news_string:\n",
    "        words.append(news.split())\n",
    "\n",
    "    final_words = []\n",
    "    for w_list in words:\n",
    "        final_words = final_words + w_list\n",
    "\n",
    "# убираем  слова 6 букв\n",
    "    words_7plus_list = []\n",
    "    for word_in_test in final_words:\n",
    "        if len(word_in_test) > 6:\n",
    "            words_7plus_list.append(word_in_test)\n",
    "\n",
    "# приводим все в нижний регистр\n",
    "    words_7plus_list_low_register = []\n",
    "    for word_in_test1 in words_7plus_list:\n",
    "        word_in_test1 = word_in_test1.lower()\n",
    "        words_7plus_list_low_register.append(word_in_test1)\n",
    "    # print(words_7plus_list_low_register)\n",
    "\n",
    "    count_dict = {}\n",
    "    for w in words_7plus_list_low_register:\n",
    "        count_dict[w] = words_7plus_list.count(w)\n",
    "\n",
    "    freq = []\n",
    "    for w1 in count_dict:\n",
    "        freq.append(count_dict[w1])\n",
    "    freq.sort(reverse=True)\n",
    "    top_10 = freq[0:10:1]\n",
    "    # print(top_10)\n",
    "\n",
    "    for w2 in count_dict:\n",
    "        if count_dict[w2] in top_10:\n",
    "            print(f\"{w2} - {count_dict[w2]}\")\n",
    "\n",
    "\n",
    "words_counter(news_reader('newsafr.json'))\n",
    "\n",
    "\n",
    "# Написать программу, которая будет выводить топ 10 самых часто встречающихся в новостях слов длиннее 6 символов для каждого файла.\n",
    "#\n",
    "# Не забываем про декомпозицию и организацию кода в функции. В решении домашнего задания вам могут помочь: split(), sort или sorted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def news_reader_xml(file_name):\n",
    "\n",
    "    parser = ET.XMLParser(encoding=\"utf-8\")\n",
    "    tree = ET.parse(file_name, parser)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    xml_items = root.findall(\"channel/item\")\n",
    "\n",
    "    news_extract = []\n",
    "    for item in xml_items:\n",
    "        news_extract.append(item.find(\"description\").text)\n",
    "        # print(item.find(\"description\").text)\n",
    "        # print(item.find(\"title\").text)\n",
    "\n",
    "    return news_extract\n",
    "\n",
    "\n",
    "def words_counter(news_string):\n",
    "\n",
    "    words = []\n",
    "    for news in news_string:\n",
    "        words.append(news.split())\n",
    "\n",
    "    final_words = []\n",
    "    for w_list in words:\n",
    "        final_words = final_words + w_list\n",
    "\n",
    "# убираем  слова меньше 6 букв\n",
    "    words_7plus_list = []\n",
    "    for word_in_test in final_words:\n",
    "        if len(word_in_test) > 6:\n",
    "            words_7plus_list.append(word_in_test)\n",
    "\n",
    "\n",
    "# приводим все в нижний регистр\n",
    "    words_7plus_list_low_register = []\n",
    "    for word_in_test1 in words_7plus_list:\n",
    "        word_in_test1 = word_in_test1.lower()\n",
    "        words_7plus_list_low_register.append(word_in_test1)\n",
    "    # print(words_7plus_list_low_register)\n",
    "\n",
    "    count_dict = {}\n",
    "    for w in words_7plus_list:\n",
    "        count_dict[w] = words_7plus_list_low_register.count(w)\n",
    "\n",
    "    freq = []\n",
    "    for w1 in count_dict:\n",
    "        freq.append(count_dict[w1])\n",
    "    freq.sort(reverse=True)\n",
    "    top_10 = freq[0:10:1]\n",
    "    # print(top_10)\n",
    "\n",
    "    for w2 in count_dict:\n",
    "        if count_dict[w2] in top_10:\n",
    "            print(f\"{w2} - {count_dict[w2]}\")\n",
    "\n",
    "\n",
    "words_counter(news_reader_xml(\"newsafr.xml\"))\n",
    "\n",
    "\n",
    "# Написать программу, которая будет выводить топ 10 самых часто встречающихся в новостях слов длиннее 6 символов для каждого файла.\n",
    "#\n",
    "# Не забываем про декомпозицию и организацию кода в функции. В решении домашнего задания вам могут помочь: split(), sort или sorted.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
